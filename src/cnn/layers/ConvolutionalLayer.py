import numpy as np

class ConvolutionalLayer:
    def __init__(self, kernel_num, kernel_size):
        """
        @param kernel_num : Number of kernels within the layer.
        @param kernel_size : Size of each kernel
        """
        self.kernel_num = kernel_num
        self.kernel_size = kernel_size
        self.kernel = np.random.randn(kernel_num, # Generate kernels (kernel sizes are squared).
                                      kernel_size, kernel_size) / (kernel_size ** 2)
        self.image = None

    def generatePatches(self, img):
        """
        Generate patches of the image which kernels have to be applied on.
        @param img : Image to process
        """
        img_height, img_width = img.shape
        self.image = img

        # Iterates through the image, 
        # kernel_size is being subtracted here due to the 
        # last step in the convolutional process.
        for h in range(img_height - self.kernel_size + 1):
            for w in range(img_width - self.kernel_size + 1):
                imgPatch = img[h : (h + self.kernel_size), w : (w + self.kernel_size)]
                yield imgPatch, h, w # Yield is here to pause execution until results are needed.

    def forwardProp(self, img):
        """
        Conduct forward propogation on the image.
        @param img : Image to process.
        @return The output generated by applying the kernels across the image.
        """
        img_height, img_width = img.shape
        # Number of output = number of total sums of matrix multiplication btw patch & kernel.
        output_shape = (img_height - self.kernel_size + 1, 
                        img_width - self.kernel_size + 1,
                        self.kernel_num)
        conv_output = np.zeros(output_shape)
        for imgPatch, h, w in self.generatePatches(img):
            # Iterate through each patch & apply kernel multiplication.
            conv_output[h, w] = np.sum(imgPatch * self.kernel, axis = (1, 2))
        return conv_output

    def backProp(self, dE_dY, alpha):
        """
        Computes gradient of loss function (E) w.r.t each 
        weight in the layer (dE_dk) and update the kernel.
        @param dE_dY : The loss from the previous layer propogated to the conv. layer.    
        @param alpha : Learning rate for gradient descent.
        @return The loss gradient with respect to the kernels.

        Works according to the following chain rule:
                dE_dk = dE_dy * dy_dk
                y = k * x
                dy_dk = x
        """

        dE_dk = np.zeros(self.kernel.shape) # Init dE_dY as zeros
        for imgPatch, h, w in self.generatePatches(self.image):
            for k in range(self.kernel_num):
                # Gradient for each point for each kernel is multiplied with imgPatch
                # to obtain error at that point.
                dE_dk[k] += imgPatch * dE_dY[h, w, k] # dE_dy * x
        self.kernel -= alpha * dE_dk # Kernel is finally updated.
        return dE_dk













